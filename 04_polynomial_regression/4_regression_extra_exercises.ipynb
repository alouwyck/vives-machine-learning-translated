{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237cf61a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alouwyck/vives-machine-learning-translated/blob/main/04_polynomial_regression/4_regression_extra_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lewAFonyBbSW",
   "metadata": {
    "id": "lewAFonyBbSW"
   },
   "source": [
    "<img src=\"data:image/png;base64,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\" align=\"right\" /><br>\n",
    "\n",
    "\n",
    "**MACHINE LEARNING FUNDAMENTALS**<br>Andy Louwyck\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_WeXDwf6bK4q",
   "metadata": {
    "id": "_WeXDwf6bK4q"
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fhk4DydHigkb",
   "metadata": {
    "id": "Fhk4DydHigkb"
   },
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Iuzlr5DsbkfM",
   "metadata": {
    "id": "Iuzlr5DsbkfM"
   },
   "source": [
    "Load the \"Diabetes\" dataset with the function `load_diabetes()` from the `datasets` module of Scikit-Learn. What features are there?\n",
    "\n",
    "Perform a linear regression to predict the target of the dataset based on the BMI of a patient. What is the RÂ², the correlation coefficient and the MSE? Is there a strong linear relationship?\n",
    "\n",
    "Make a scatterplot of the data and add the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UjgwRmPYqcjd",
   "metadata": {
    "id": "UjgwRmPYqcjd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51RGzCdEW5u0",
   "metadata": {
    "id": "51RGzCdEW5u0"
   },
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ie3wtqoec5B0",
   "metadata": {
    "id": "ie3wtqoec5B0"
   },
   "source": [
    "[Kaggle](https://www.kaggle.com/) is an online community for people who are involved in data science and machine learning. You will find many interesting datasets with accompanying example code. Kaggle is also known for the competitions it organizes.\n",
    "\n",
    "In this exercise we will download a simple dataset from Kaggle with features of houses: the surface area, the number of bedrooms, the age of the house and the price. The intention is to train a regression model based on this dataset with which we can then predict the price of a new house. Because we have 3 independent variables here (the features surface area, number of bedrooms and the age) and 1 dependent variable (the target price) we speak of **multivariate linear regression**. Synonyms are multivariable or multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lpbrd84XfwEN",
   "metadata": {
    "id": "lpbrd84XfwEN"
   },
   "source": [
    "The dataset can be found here:\n",
    "\n",
    "https://www.kaggle.com/code/pankeshpatel/ml-for-beginners-2-multivariate-regression/data.\n",
    "\n",
    "Read the csv file and check if there are any missing values. You will notice that one value is missing for the number of bedrooms. Fill that value with the median of that variable. Of course you use code for this! For example, check Pandas method [`fillna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)\n",
    "\n",
    "In a next step we will check if we can effectively apply linear regression to the data. In other words, is there a linear relationship between the features and the target? We can use plot functions from the [seaborn](https://seaborn.pydata.org/) library for this, which is based on matplotlib and has been specially developed for creating statistical plots.\n",
    "\n",
    "Create a [`pairplot`](https://seaborn.pydata.org/generated/seaborn.pairplot.html#seaborn.pairplot) of the data and check whether there is indeed a linear relationship between the price and the other features. In addition to a visual check, we can of course also calculate the correlation coefficient. In a multivariate analysis we draw up a correlation matrix for this. Check Pandas method [`corr`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html). Visualize the matrix with the [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function of `seaborn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1U-4ZaFhW8b",
   "metadata": {
    "id": "F1U-4ZaFhW8b"
   },
   "source": [
    "This first phase of exploring the data is called **exploratory data analysis** (EDA). If you have set up the correlation matrix correctly, you will find that there is indeed a linear relationship between features and targets. So you can now apply linear regression using the `LinearRegression` class of `sklearn`. This is of course the **training phase**. Calculate the RÂ² score and the Mean Absolute Error (MAE) to evaluate the obtained model.\n",
    "\n",
    "Once the model has been trained and evaluated, we enter the **inference phase** in which we will make predictions with new data. Do this here for a house that is 5 years old, has 8 bedrooms and a surface area of ââ5000. What do you estimate the cost price of that house to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qj4-MK3Y3fUI",
   "metadata": {
    "id": "qj4-MK3Y3fUI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eZthAYVYpbjE",
   "metadata": {
    "id": "eZthAYVYpbjE"
   },
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6CukcFYmpeNW",
   "metadata": {
    "id": "6CukcFYmpeNW"
   },
   "source": [
    "We can create our own datasets for linear regression using the function [`make_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression) from the `sklearn.datasets` module.\n",
    "\n",
    "As an example, we generate a dataset with 10 samples for simple linear regression. This is a dataset consisting of 1 feature `x` and 1 target `y`. We add a `bias` of -3, which is another word for intercept, and `noise` with a standard deviation of 20.\n",
    "\n",
    "Note that we also have to specify the number of 'informative' features here. These are features that effectively correlate with the target. In this case, we have 1 informative feature.\n",
    "\n",
    "We fit the dataset using the `LinearRegression` class of module `sklearn.linear_model`, calculate the RÂ² score, and finally plot the dataset with the regression line using basic pyplot functions and function [`lmplot`](https://seaborn.pydata.org/generated/seaborn.lmplot.html#seaborn.lmplot) of `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "esU4Z94Q3ksq",
   "metadata": {
    "id": "esU4Z94Q3ksq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "jkELpNOwvKnb",
   "metadata": {
    "id": "jkELpNOwvKnb"
   },
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1DqIwHIcvMUx",
   "metadata": {
    "id": "1DqIwHIcvMUx"
   },
   "source": [
    "We use the `make_regression` function again to generate a dataset for multivariate linear regression. We take 1000 samples, 10 features of which 5 informative, 1 target, a bias of 15, and add noise with a standard deviation of 50.\n",
    "\n",
    "We put the features and the target in a Pandas DataFrame. This way we can retrieve the most important statistics using the `describe` method. We can also quickly calculate the correlation matrix and see that indeed only 5 out of 10 features correlate with the target. Finally, we fit the dataset using a linear regression model and calculate the RÂ² score, the MAE and the MSE to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jb-9SEmo3qkX",
   "metadata": {
    "id": "jb-9SEmo3qkX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "radio-edgar",
   "metadata": {
    "id": "radio-edgar"
   },
   "source": [
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RfeBUm0P37i3",
   "metadata": {
    "id": "RfeBUm0P37i3"
   },
   "source": [
    "## Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-frontier",
   "metadata": {
    "id": "stretch-frontier"
   },
   "source": [
    "We want to test polynomial regression and for that we are going to create a fictitious dataset using a polynomial function of which we know the equation:\n",
    "\n",
    "> $y = -x^2 + x + 15$\n",
    "\n",
    "We write a function ourselves to calculate `y` values ââbased on given `x` values. In this way we ensure that our code is reusable! We use the following function definition\n",
    "\n",
    "```\n",
    "def polynomial(coefs, x):\n",
    "```\n",
    "We test our function by generating values ââfor `x` between -5 and 5. We can use the function `np.linspace` for that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FAI4xP4NqfZZ",
   "metadata": {
    "id": "FAI4xP4NqfZZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incident-telling",
   "metadata": {
    "id": "incident-telling"
   },
   "source": [
    "Now we plot those points on a graph and define a function again:\n",
    "```\n",
    "def draw_polynomial(coefs, x):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XxHkLiMYqhLD",
   "metadata": {
    "id": "XxHkLiMYqhLD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ypNmcbaJ4H7o",
   "metadata": {
    "id": "ypNmcbaJ4H7o"
   },
   "source": [
    "Now we are going to generate a scatter plot around that quadratic curve. We generate X values ââin the interval $[-5,5]$. For the points on the Y-axis we use the polynomial function and add **noise** using the following formula:\n",
    "```\n",
    "polynomial(coefs, x) + random.gauss(mu=0, sigma=1.5)\n",
    "```\n",
    "\n",
    "Function `random.gauss` generates a random number that follows a normal distribution with mean `mu` and standard deviation `sigma`.\n",
    "\n",
    "We generate 10 points and store the coordinates in a list called X and Y, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OS6yb_kvqjLx",
   "metadata": {
    "id": "OS6yb_kvqjLx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "I9mY3EOz4POb",
   "metadata": {
    "id": "I9mY3EOz4POb"
   },
   "source": [
    "We visualize the generated data points on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GF4EJcDRqkc5",
   "metadata": {
    "id": "GF4EJcDRqkc5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "o0F-gcA_4Tj1",
   "metadata": {
    "id": "o0F-gcA_4Tj1"
   },
   "source": [
    "## Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l9SmxjmO4Tj2",
   "metadata": {
    "id": "l9SmxjmO4Tj2"
   },
   "source": [
    "On the point cloud we generated, we now try out different models. First, we put the points in a data frame, and sort the generated data points along the X-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d-ZvlDbkqqLC",
   "metadata": {
    "id": "d-ZvlDbkqqLC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "MGHDGC1U4Z62",
   "metadata": {
    "id": "MGHDGC1U4Z62"
   },
   "source": [
    "We visualize the data points in the data frame again using a scatter plot to check whether the conversion to a data frame and the sorting were successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H2Me8mcTqrZO",
   "metadata": {
    "id": "H2Me8mcTqrZO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eKbMp1Xs4fB_",
   "metadata": {
    "id": "eKbMp1Xs4fB_"
   },
   "source": [
    "In the following code we show how we can apply polynomial regression using SciKit-Learn. We try out 4 models: a linear model, and three polynomial models of degree 2, 5 and 10.\n",
    "We place these plots next to each other and also print the MSE per plot.\n",
    "Such a plot can be used as a visual inspection of different models.\n",
    "To evaluate overfitting, cross validation is used. We repeatedly reserve a piece of the training set as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h0Zhixk5597t",
   "metadata": {
    "id": "h0Zhixk5597t"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-centre",
   "metadata": {
    "id": "natural-centre",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "degrees = [1, 2, 5, 10]\n",
    "\n",
    "# select feature and label from data frame \"data\"\n",
    "X_train = data['x'].to_numpy()\n",
    "y_train = data['y'].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "for i in range(len(degrees)):\n",
    "\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    # Make pipeline for polynomial regression and fit data\n",
    "    polynomial_features = PolynomialFeatures(\n",
    "        degree=degrees[i],\n",
    "        include_bias=False Set # to False because intercept/bias is also included in LinearRegression!\n",
    "    )\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X_train[:, np.newaxis], y_train) # X must be 2D matrix!\n",
    "\n",
    "    # Validate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X_train[:, np.newaxis], y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", # neg_mean_squared error = -MSE\n",
    "                             cv=10) # cv is the number of folds\n",
    "\n",
    "    # Regression curve\n",
    "    X_curve = np.linspace(-5, 5, 100)\n",
    "    Y_curve = pipeline.predict(X_curve[:, np.newaxis])\n",
    "    Y_true = polynomial(coefs, X_curve) # original model\n",
    "\n",
    "    #Plot\n",
    "    plt.plot(X_curve, Y_curve, label=\"Model\")\n",
    "    plt.plot(X_curve, Y_true, label=\"True function\")\n",
    "    plt.scatter(X_train, y_train, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((-5, 5))\n",
    "    plt.ylim((-20, 20))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-proportion",
   "metadata": {
    "id": "dutch-proportion"
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wEvikKwa4qnF",
   "metadata": {
    "id": "wEvikKwa4qnF"
   },
   "source": [
    "## Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VSBbGPD04qnG",
   "metadata": {
    "id": "VSBbGPD04qnG"
   },
   "source": [
    "We are now going to apply polynomial regression with regularization to the dataset we generated. We use a polynomial of degree 10. First, we perform the regression without regularization so that we can clearly see the effect.\n",
    "\n",
    "We base ourselves on the code above, but this time we do not apply cross-validation. We plot the result on a figure and make sure that the figure shows both the original polynomial function, the data cloud, and the regression curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E6ujR-MnrEl8",
   "metadata": {
    "id": "E6ujR-MnrEl8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "C_4XxCel40Rc",
   "metadata": {
    "id": "C_4XxCel40Rc"
   },
   "source": [
    "We now do the same thing but this time we apply **Ridge regression**. We use the following code for this:\n",
    "\n",
    "> `polyreg=make_pipeline(PolynomialFeatures(degree, include_bias=False), Ridge(alpha=0.1, tol=0.1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VxxdmpWjrGZf",
   "metadata": {
    "id": "VxxdmpWjrGZf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Wtz7Qujr44P9",
   "metadata": {
    "id": "Wtz7Qujr44P9"
   },
   "source": [
    "Finally, we also apply **Lasso regression**. For this we use the following code:\n",
    "\n",
    "> `polyreg=make_pipeline(PolynomialFeatures(degree, include_bias=False), Lasso(alpha=0.1, tol=0.1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-WAktvAIrJOr",
   "metadata": {
    "id": "-WAktvAIrJOr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lpPUCv7e-i41",
   "metadata": {
    "id": "lpPUCv7e-i41"
   },
   "source": [
    "# Training, validating, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_1tCFoLb-oED",
   "metadata": {
    "id": "_1tCFoLb-oED"
   },
   "source": [
    "## Assignment 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MBkT3WGzltRa",
   "metadata": {
    "id": "MBkT3WGzltRa"
   },
   "source": [
    "In this assignment we illustrate the full training phase with **simple hold-out validation**. We also test the selected model, and do a final training on the full dataset to arrive at our final model.\n",
    "\n",
    "Read the dataset \"LinkedIn.csv\" as a Pandas dataframe.\n",
    "\n",
    "Split your dataset as follows: take 500 random data points for each validation and test set; the remaining data points form the training set. Tip: check scikit-learn function `train_test_split`.\n",
    "\n",
    "Apply simple linear regression and 2nd degree polynomial regression to the training set. Calculate the MSE for each training and validation set. Which model do you choose?\n",
    "\n",
    "Evaluate the selected model with the test set. Do you get an equally good result? If so, train your final model on the full set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2sVCnoFHrP9W",
   "metadata": {
    "id": "2sVCnoFHrP9W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7OAp2GQ1iVZR",
   "metadata": {
    "id": "7OAp2GQ1iVZR"
   },
   "source": [
    "## Assignment 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lw_9Hxb4iSiI",
   "metadata": {
    "id": "lw_9Hxb4iSiI"
   },
   "source": [
    "In this assignment, we illustrate the full training phase with **K-fold cross-validation**. We also test the selected model, and do a final training on the full dataset to arrive at our final model.\n",
    "\n",
    "Read the dataset \"LinkedIn.csv\" as a Pandas dataframe.\n",
    "\n",
    "Split your dataset as follows: take 500 random data points for the test set; the remaining data points form the training set. Tip: check scikit-learn function `train_test_split`.\n",
    "\n",
    "Apply simple linear regression and 2nd degree polynomial regression to the training set. Apply K-fold cross-validation with 15 folds. Tip: check scikit-learn function `cross_validate`. Calculate the average MSE for training and validation for both. Which model do you choose?\n",
    "\n",
    "Retrain the selected model on the full training set and evaluate with the test set. Do you get an equally good result? If so, train your final model on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mci9f8NFrZrJ",
   "metadata": {
    "id": "Mci9f8NFrZrJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
